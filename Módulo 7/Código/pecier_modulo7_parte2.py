# -*- coding: utf-8 -*-
"""PECIER_dia7_parte2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IeEc61aiedFGbwoJmaP75AaSasRNecP8

# Día 7 Parte 2: Uso de APIs para interactuar con Modelos de Lenguaje (LLMs) como GPT

## Ejemplos

**Ejemplo 7.5:**
"""

# Ejemplo básico de conexión a la API de OpenAI
import openai

openai.api_key = "tu-api-key"  # Nunca expongas esto en código público

response = openai.ChatCompletion.create(
  model="gpt-4",
  messages=[{"role": "user", "content": "Explica cómo funciona un transformador eléctrico"}]
)

print(response.choices[0].message.content)

"""## Ejercicios

**Ejercicio 7.2: Asistente para Normativas Eléctricas**
1. Crea un asistente que responda preguntas sobre la norma IEEE 1547
2. Implementa memoria de conversación (3-5 mensajes de historial)
3. Añade capacidad de citar secciones específicas de la norma

**Ejercicio 7.3: Traductor Técnico**
1. Desarrolla un sistema que traduzca informes técnicos inglés-español
2. Manteniendo terminología eléctrica precisa
3. Con opción de explicar conceptos complejos al final

**Ejercicio 7.4: Generador de Procedimientos**
1. Crea una función que genere procedimientos de mantenimiento
2. Basado en tipo de equipo (transformador, interruptor, etc.)
3. Y nivel de experiencia del técnico (junior, senior)

### Solución Ejercicio 1: Asistente para Normativas
```python
import openai
from collections import deque

class AsistenteNormativas:
    def __init__(self):
        self.historial = deque(maxlen=5)  # Memoria de conversación
        self.contexto = '''
        Eres un experto en la norma IEEE 1547 para interconexión de recursos distribuidos.
        Responde preguntas técnicas citando los artículos relevantes.
        Sé preciso y usa lenguaje profesional.
        '''
        
    def preguntar(self, consulta):
        self.historial.append({"role": "user", "content": consulta})
        
        messages = [{"role": "system", "content": self.contexto}]
        messages.extend(self.historial)
        
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=messages,
            temperature=0.3
        )
        
        respuesta = response.choices[0].message.content
        self.historial.append({"role": "assistant", "content": respuesta})
        return respuesta

# Uso
asistente = AsistenteNormativas()
print(asistente.preguntar("¿Cuáles son los requisitos de protección anti-isla para generadores < 30kW?"))
```

## Proyecto-: Sistema de Asistencia Técnica Integrado

**Objetivo:** Crear un sistema que:
1. Analice datos SCADA en tiempo real
2. Genere alertas inteligentes
3. Proporcione recomendaciones accionables
4. Documente incidentes automáticamente

```python
import openai
import pandas as pd
from datetime import datetime

class AsistenteSCADA:
    def __init__(self):
        self.contexto = '''
        Eres un ingeniero de sistemas de potencia experimentado.
        Analiza datos de SCADA y proporciona recomendaciones técnicas.
        '''
    
    def analizar_datos(self, datos):
        prompt = f'''
        Analiza estos datos de SCADA:
        {datos.to_markdown()}
        
        Identifica:
        1. Anomalías o valores fuera de rango
        2. Posibles causas
        3. Acciones recomendadas
        4. Prioridad (Alta, Media, Baja)
        '''
        
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": self.contexto},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2
        )
        
        return response.choices[0].message.content

# Ejemplo de uso
datos = pd.DataFrame({
    "Parámetro": ["Voltaje L1", "Voltaje L2", "Voltaje L3", "Temp. Transformador"],
    "Valor": [132.4, 131.8, 85.2, 78],
    "Límite": ["130±5%", "130±5%", "130±5%", "75 max"]
})

asistente = AsistenteSCADA()
print(asistente.analizar_datos(datos))
```
"""